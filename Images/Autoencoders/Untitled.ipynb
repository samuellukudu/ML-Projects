{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f75c2b3-cbc4-468e-9ede-13db8d72d562",
   "metadata": {},
   "source": [
    "# SPARSE AUTOENCODERS\n",
    "\n",
    "A sparse autoencoder is a type of neural network architecture that is used for unsupervised learning. It is an extension of a basic autoencoder and involves adding a sparsity constraint to the learning process. The idea is to encourage the encoder to learn a compact representation of the input data, where most of the activations in the hidden layer are zero (i.e., sparse). This results in a more interpretable and computationally efficient representation of the data. The sparse constraint is typically achieved by adding a sparsity regularization term to the loss function, which penalizes the network if the average activation degree of the hidden layer neurons exceeds a certain threshold. The sparse autoencoder can be used for various tasks such as image compression, feature learning, and dimensionality reduction.\n",
    "\n",
    "Yes, the average activation degree of hidden layer neurons is commonly used in the training process of sparse autoencoders. Sparse autoencoders aim to encourage the hidden layer neurons to have low activation values for most of the inputs, only a small percentage of neurons would activate for a given input. The sparsity constraint can be achieved by adding a sparsity loss term to the autoencoder's loss function which encourages a target average activation degree for the hidden layer neurons. The average activation degree of the hidden layer neurons is usually calculated as the mean activation across all neurons and all inputs in a batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7de10b-eadb-423b-8266-4b5142a8dee7",
   "metadata": {},
   "source": [
    "## AVERAGE ACTIVATION DEGREE OF A HIDDEN LAYER\n",
    "The average activation degree of a hidden layer neuron in a neural network is the **average output of the activation function applied to the weighted sum of inputs from the previous layer**. It measures the level of activation of the neuron and its contribution to the overall output of the network. The activation degree is calculated for each neuron and can vary between 0 and 1 for binary activation functions, such as the sigmoid function, or between negative and positive values for other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de661138-a7b8-44db-be68-85756c6ccd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868e43e45aba41fa9432a833dbe86db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/10] Train Loss: 36.2877, Train MAPE: 1.5438, Train Acc: 98.4562\n",
      "Epoch: [0/10] Test Loss: 30.1308, Test MAPE: 1.3893, Test Acc: 98.6107\n",
      "\n",
      "Epoch: [1/10] Train Loss: 31.0789, Train MAPE: 1.4962, Train Acc: 98.5038\n",
      "Epoch: [1/10] Test Loss: 27.4427, Test MAPE: 1.3795, Test Acc: 98.6205\n",
      "\n",
      "Epoch: [2/10] Train Loss: 29.2663, Train MAPE: 1.5112, Train Acc: 98.4888\n",
      "Epoch: [2/10] Test Loss: 25.9166, Test MAPE: 1.3777, Test Acc: 98.6223\n",
      "\n",
      "Epoch: [3/10] Train Loss: 28.3035, Train MAPE: 1.4835, Train Acc: 98.5165\n",
      "Epoch: [3/10] Test Loss: 25.1895, Test MAPE: 1.3791, Test Acc: 98.6209\n",
      "\n",
      "Epoch: [4/10] Train Loss: 27.6367, Train MAPE: 1.4792, Train Acc: 98.5208\n",
      "Epoch: [4/10] Test Loss: 24.9073, Test MAPE: 1.3751, Test Acc: 98.6249\n",
      "\n",
      "Epoch: [5/10] Train Loss: 27.3457, Train MAPE: 1.3975, Train Acc: 98.6025\n",
      "Epoch: [5/10] Test Loss: 24.3469, Test MAPE: 1.3739, Test Acc: 98.6261\n",
      "\n",
      "Epoch: [6/10] Train Loss: 27.0100, Train MAPE: 1.4349, Train Acc: 98.5651\n",
      "Epoch: [6/10] Test Loss: 24.2027, Test MAPE: 1.3793, Test Acc: 98.6207\n",
      "\n",
      "Epoch: [7/10] Train Loss: 26.8175, Train MAPE: 1.3838, Train Acc: 98.6162\n",
      "Epoch: [7/10] Test Loss: 24.0341, Test MAPE: 1.3718, Test Acc: 98.6282\n",
      "\n",
      "Epoch: [8/10] Train Loss: 26.7920, Train MAPE: 1.4194, Train Acc: 98.5806\n",
      "Epoch: [8/10] Test Loss: 24.1960, Test MAPE: 1.3801, Test Acc: 98.6199\n",
      "\n",
      "Epoch: [9/10] Train Loss: 26.5702, Train MAPE: 1.4188, Train Acc: 98.5812\n",
      "Epoch: [9/10] Test Loss: 23.9736, Test MAPE: 1.3801, Test Acc: 98.6199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the digits dataset from scikit-learn\n",
    "digits = load_digits()\n",
    "X = digits.images\n",
    "y = digits.target\n",
    "\n",
    "# Reshape the images to be in the form (number of samples, number of features)\n",
    "X = X.reshape((len(X), -1))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float)\n",
    "\n",
    "# Create custom activation functions\n",
    "class Satlin(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # return torch.where(x > 0, x, x/(1 + torch.abs(x)))\n",
    "        return torch.clamp(x, 0, 1)\n",
    "    \n",
    "class Purelin(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "# MAPE Metric for evaluation\n",
    "class Mape(nn.Module):\n",
    "    def forward(self, true, pred):\n",
    "        num = torch.sum(torch.abs(true - pred))\n",
    "        den = torch.sum(torch.abs(true)) * true.shape[0]\n",
    "        mape = 100 * (num/den)\n",
    "        return mape\n",
    "    \n",
    "\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, sparsity_param, beta):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sparsity_param = sparsity_param\n",
    "        self.beta = beta\n",
    "        self.satlin = Satlin()\n",
    "        self.purelin = Purelin()\n",
    "        \n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.satlin(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.purelin(x)\n",
    "        \n",
    "        avg_act = torch.mean(x, dim=0)\n",
    "        \n",
    "        # sparsity_loss = self.sparsity_param * torch.log(self.sparsity_param / avg_act) + \\\n",
    "        #     (1 - self.sparsity_param) * torch.log((1 - self.sparsity_param) / (1 - avg_act))\n",
    "        sparsity_loss = self.sparsity_param * torch.log(self.sparsity_param / avg_act) + \\\n",
    "                        torch.log((1-self.sparsity_param)/(1-avg_act))\n",
    "        \n",
    "        sparsity_loss = self.beta * torch.sum(sparsity_loss)\n",
    "        \n",
    "        return x, sparsity_loss\n",
    "    \n",
    "def train(model, train_loader, criterion, optimizer, beta):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, sparsity_loss = model(data)\n",
    "        loss = criterion(outputs, data) + sparsity_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        m = mape(data, outputs)\n",
    "    return train_loss / len(train_loader), m\n",
    "\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    for data in test_loader:\n",
    "        with torch.no_grad():\n",
    "            outputs, _ = model(data)\n",
    "            loss = criterion(data, outputs)\n",
    "            m = mape(data, outputs)\n",
    "            test_loss += loss\n",
    "    # print(f\"Test loss: {test_loss/len(test_loader):.4f}, Test MAPE: {m:.4f}\")\n",
    "    return test_loss/len(test_loader), m\n",
    "\n",
    "input_size = 64\n",
    "hidden_size = 100\n",
    "sparsity_param = 0.05\n",
    "beta = 3\n",
    "\n",
    "model = SparseAutoencoder(input_size, hidden_size, sparsity_param, beta)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "mape = Mape()\n",
    "\n",
    "# Replace this with your own data loading code\n",
    "train_loader = X_train\n",
    "test_loader = X_test\n",
    "\n",
    "n_epochs = 10\n",
    "for epoch, _ in enumerate(tqdm(range(n_epochs), desc='Training model', total=n_epochs)):\n",
    "    train_loss, m = train(model, train_loader, criterion, optimizer, beta)\n",
    "    test_loss, test_m = test(model, test_loader, criterion)\n",
    "    \n",
    "    acc = 100 - m\n",
    "    test_acc = 100 - test_m\n",
    "    print(f\"Epoch: [{epoch}/{n_epochs}] Train Loss: {train_loss:.4f}, Train MAPE: {m:.4f}, Train Acc: {acc:.4f}\")\n",
    "    print(f\"Epoch: [{epoch}/{n_epochs}] Test Loss: {test_loss:.4f}, Test MAPE: {test_m:.4f}, Test Acc: {test_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c72fec9-1e05-400b-a3c7-c0c767158fb6",
   "metadata": {},
   "source": [
    "# Variational Autoencoder\n",
    "\n",
    "Variational Autoencoders (VAE) are a type of generative model that can be used for various applications including:\n",
    "\n",
    "* Data generation: VAEs can be used to generate new data points that are similar to the training data by sampling from the encoded latent space.\n",
    "\n",
    "* Data compression: VAEs can be used as an unsupervised learning method for compressing high-dimensional data into a lower dimensional latent space, where the data can be reconstructed with a lower error.\n",
    "\n",
    "* Data visualization: By projecting high-dimensional data into a 2D latent space, VAEs can be used to visualize complex data structures and relationships.\n",
    "\n",
    "* Anomaly detection: VAEs can be used to identify anomalies in data by monitoring the reconstruction error and identifying cases where the difference between the input and reconstructed data is large.\n",
    "\n",
    "* Recommendation systems: By learning to encode the underlying patterns of a dataset, VAEs can be used to make recommendations based on similar patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d62f77-b2de-45dd-86a7-7168b7cd2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, latent_dim * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        mean, log_var = x[:, :latent_dim], x[:, latent_dim:]\n",
    "        return mean, log_var\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encoder(x)\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        z = mean + std * epsilon\n",
    "        reconstructed_x = self.decoder(z)\n",
    "        return reconstructed_x, mean, log_var\n",
    "\n",
    "input_dim = 784 # 28x28 images\n",
    "hidden_dim = 128\n",
    "latent_dim = 32\n",
    "\n",
    "model = VAE(input_dim, hidden_dim, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ed71a-c471-4ba0-890d-560a04aa1b3f",
   "metadata": {},
   "source": [
    "### Reconstruction and KL-divergence loss for VAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea8bc13-823e-4eba-a386-90169e89aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dims=(512, 256)):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder network\n",
    "        self.encoder_hidden = nn.ModuleList()\n",
    "        in_dims = [input_dim] + list(hidden_dims)\n",
    "        for i in range(len(hidden_dims)):\n",
    "            self.encoder_hidden.append(nn.Linear(in_dims[i], in_dims[i+1]))\n",
    "        \n",
    "        self.mean = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.logvar = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        \n",
    "        # Decoder network\n",
    "        self.decoder_hidden = nn.ModuleList()\n",
    "        out_dims = list(reversed(hidden_dims)) + [input_dim]\n",
    "        for i in range(len(hidden_dims)):\n",
    "            self.decoder_hidden.append(nn.Linear(out_dims[i], out_dims[i+1]))\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = x\n",
    "        for layer in self.encoder_hidden:\n",
    "            h = F.relu(layer(h))\n",
    "        mean = self.mean(h)\n",
    "        logvar = self.logvar(h)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = z\n",
    "        for layer in self.decoder_hidden:\n",
    "            h = F.relu(layer(h))\n",
    "        return torch.sigmoid(h)\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, mean, logvar\n",
    "    \n",
    "def vae_loss(recon_x, x, mean, logvar):\n",
    "    recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b96120-adff-4989-bdb7-6fe4e75a3a93",
   "metadata": {},
   "source": [
    "# DENOISING AUTOENCODER\n",
    "\n",
    "A denoising autoencoder is a type of autoencoder that is trained to reconstruct the original input from a corrupted version of it. The purpose is to learn a robust representation that is able to recover the original signal from noisy or incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b95bd51-baaa-4e6e-994b-d09f80ad3de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 6.0891\n",
      "Epoch 2 loss: 1.0729\n",
      "Epoch 3 loss: 0.4547\n",
      "Epoch 4 loss: 0.2394\n",
      "Epoch 5 loss: 0.1770\n",
      "Epoch 6 loss: 0.1567\n",
      "Epoch 7 loss: 0.1547\n",
      "Epoch 8 loss: 0.1453\n",
      "Epoch 9 loss: 0.1415\n",
      "Epoch 10 loss: 0.1492\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + torch.randn_like(x) * 0.1\n",
    "        x = F.relu(self.encoder(x))\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Define the model, criterion, optimizer\n",
    "model = DenoisingAutoencoder(input_size, hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch {} loss: {:.4f}'.format(epoch + 1, running_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3c3afa-0358-4f08-bf57-587a4e1af58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
